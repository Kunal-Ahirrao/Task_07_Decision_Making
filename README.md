# ðŸ§­ Task_07_Decision_Making â€” SU Womenâ€™s Lacrosse (2023â€“2025)

**Goal:** Turn the Task 06 LLM-produced *sideline interview* into a stakeholder-facing decision report with a rigorous **ethics, reliability, and reproducibility** spine.  
**Source context:** Builds on **Task 04** (descriptive stats), **Task 05** (LLM Q&A over dataset), and **Task 06** (deep-fake interview).  
**Status:** Submission-ready scaffold using official SU Womenâ€™s Lacrosse stats (2023â€“2025).

---

## ðŸ“¦ Repository Structure

```
Task_07_Decision_Making/
â”œâ”€â”€ archives/
â”‚   â”œâ”€â”€ task4/                      # Imported artifacts from Task 4 (for audit)
â”‚   â””â”€â”€ task5/                      # Imported artifacts from Task 5 (for audit)
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ config.example.yaml          # Copy to config.yaml and edit paths if needed
â”‚   â””â”€â”€ config.yaml                  # Points to data/raw/lacrosse_stats.csv
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/
â”‚   â”‚   â””â”€â”€ lacrosse_stats.csv       # Consolidated period-level dataset (2023â€“2025)
â”‚   â””â”€â”€ processed/                   # Generated by scripts (if any)
â”œâ”€â”€ ethics/
â”‚   â””â”€â”€ ETHICS_CHECKLIST.md
â”œâ”€â”€ logs/
â”‚   â””â”€â”€ llm_prompt_log.md            # Full prompts, raw outputs, and edit notes
â”œâ”€â”€ outputs/                         # Mirrors results/ for convenience
â”‚   â”œâ”€â”€ figures/
â”‚   â””â”€â”€ tables/
â”œâ”€â”€ prompts/
â”‚   â””â”€â”€ decision_prompt_template.txt
â”œâ”€â”€ reports/
â”‚   â”œâ”€â”€ stakeholder_report.md        # Main report (ready to finalize)
â”‚   â””â”€â”€ stakeholder_report_template.md
â”œâ”€â”€ results/
â”‚   â”œâ”€â”€ figures/
â”‚   â”œâ”€â”€ report/
â”‚   â”‚   â”œâ”€â”€ APPENDIX_TASK4_TASK5.md  # Inventory of imported Task 4/5 files
â”‚   â”‚   â””â”€â”€ stakeholder_report.md    # Same content as reports/, for grading
â”‚   â””â”€â”€ tables/
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ analysis_descriptives.py     # Describe, value counts, quick histograms
â”‚   â”œâ”€â”€ bootstrap_ci.py              # Non-parametric CI for Aâ€“B mean differences
â”‚   â”œâ”€â”€ fairness_checks.py           # Subgroup disparity table
â”‚   â”œâ”€â”€ data_validation.py           # Missingness/outliers summary
â”‚   â”œâ”€â”€ descriptive_stats.py         # Topline stats + example CIs
â”‚   â”œâ”€â”€ sensitivity_analysis.py      # Remove top-N / normalization checks
â”‚   â”œâ”€â”€ stats_tests.py               # Paired tests (e.g., 1st vs 2nd half)
â”‚   â”œâ”€â”€ visualization.py             # Minute/period trend plots
â”‚   â””â”€â”€ run_pipeline.py              # Runs the full analysis sequence
â”œâ”€â”€ seeds.json                       # Canonical seeds / run metadata
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .gitignore
â””â”€â”€ LICENSE
```

> **Note:** `outputs/` mirrors `results/` so you can reference tables/figures consistently in your report.

---

## ðŸš€ Quickstart

1) (Optional) Create a virtual environment and install deps:
```bash
python -m venv .venv
source .venv/bin/activate        # Windows: .venv\Scripts\activate
pip install -r requirements.txt
```

2) **Data is already wired**: `data/raw/lacrosse_stats.csv` (period-level stats for 2023â€“2025).  
If you replace or add data, update `config/config.yaml`.

3) **Run the full pipeline** (writes tables & figures to `results/` and mirrors to `outputs/`):
```bash
python scripts/run_pipeline.py
```

4) **Targeted commands** (if you want to run individual analyses):

- Descriptive profile (describe, value-counts, histograms):
```bash
python scripts/analysis_descriptives.py   --data data/raw/lacrosse_stats.csv   --out outputs   --seed 42
```

- Bootstrap CI for a difference in means (e.g., goals: 1st half vs 2nd half):
```bash
python scripts/bootstrap_ci.py   --data data/raw/lacrosse_stats.csv   --col goals   --by period   --diff "2nd-1st"   --iters 5000   --out outputs/tables/goals_diff_ci.csv   --seed 4242
```

- Fairness/subgroup disparity (example uses year as subgroup; add others if present):
```bash
python scripts/fairness_checks.py   --data data/raw/lacrosse_stats.csv   --group-cols year   --target goals   --out outputs/tables/fairness_summary.csv
```

---

## ðŸ§ª Whatâ€™s Included in the Report

The stakeholder report (`reports/stakeholder_report.md`) includes:

- **Executive one-liner with tiered recommendations:**
  - **Operational (low risk):** Endurance + shot-selection micro-drills post-minute-30; instrument practices.
  - **Investigatory (medium risk):** A/B scrimmage trial of hydration + pacing; pre-registered metrics; 95% CIs.
  - **High-stakes (high risk):** Rotation/lineup changes contingent on monitored endurance metrics (human/HR/legal review).

- **Uncertainty:** 95% bootstrap confidence intervals; sensitivity checks (remove top 5%; normalization).  
- **Fairness:** Subgroup coverage & disparity table.  
- **Ethics/Legal:** FERPA/privacy; LLM labeling; human-in-the-loop for personnel actions.  
- **Appendix:** Full list of imported Task 4/5 artifacts; prompts & raw LLM outputs logged in `logs/llm_prompt_log.md`.

---

## ðŸ›¡ï¸ Reproducibility

- All scripts accept `--seed` and print the seed used.  
- Canonical seeds and run markers live in `seeds.json`.  
- **Tables/figures** are materialized in `results/` and mirrored in `outputs/`.  

To pin your exact environment:
```bash
pip freeze > requirements.txt
```

---

## ðŸ“¬ Submission

1) Push the repo to GitHub as **Task_07_Decision_Making** (keep large/raw private if needed).  
2) Email the public repo link to **jrstrome@syr.edu** (not Dr. Stromer-Galley).  
3) Report progress via the **Qualtrics** check-in by **Oct 1**.

---

## âœ… Notes

- LLM content from **Task 06** (sideline interview) is **clearly labeled** in the report and verified against data.  
- The consolidated dataset aggregates official SU Womenâ€™s Lacrosse period-level stats from **2023â€“2025** (Goals/SOG/Shots/Saves; OT where available).  
- High-stakes actions (e.g., personnel/lineup decisions) **require human review** and may require HR/Legal sign-off.
