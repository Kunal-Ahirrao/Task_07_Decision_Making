# 🧭 Task_07_Decision_Making — SU Women’s Lacrosse (2023–2025)

**Goal:** Turn the Task 06 LLM-produced *sideline interview* into a stakeholder-facing decision report with a rigorous **ethics, reliability, and reproducibility** spine.  
**Source context:** Builds on **Task 04** (descriptive stats), **Task 05** (LLM Q&A over dataset), and **Task 06** (deep-fake interview).  
**Status:** Submission-ready scaffold using official SU Women’s Lacrosse stats (2023–2025).

---

## 📦 Repository Structure

```
Task_07_Decision_Making/
├── archives/
│   ├── task4/                      # Imported artifacts from Task 4 (for audit)
│   └── task5/                      # Imported artifacts from Task 5 (for audit)
├── config/
│   ├── config.example.yaml          # Copy to config.yaml and edit paths if needed
│   └── config.yaml                  # Points to data/raw/lacrosse_stats.csv
├── data/
│   ├── raw/
│   │   └── lacrosse_stats.csv       # Consolidated period-level dataset (2023–2025)
│   └── processed/                   # Generated by scripts (if any)
├── ethics/
│   └── ETHICS_CHECKLIST.md
├── logs/
│   └── llm_prompt_log.md            # Full prompts, raw outputs, and edit notes
├── outputs/                         # Mirrors results/ for convenience
│   ├── figures/
│   └── tables/
├── prompts/
│   └── decision_prompt_template.txt
├── reports/
│   ├── stakeholder_report.md        # Main report (ready to finalize)
│   └── stakeholder_report_template.md
├── results/
│   ├── figures/
│   ├── report/
│   │   ├── APPENDIX_TASK4_TASK5.md  # Inventory of imported Task 4/5 files
│   │   └── stakeholder_report.md    # Same content as reports/, for grading
│   └── tables/
├── scripts/
│   ├── analysis_descriptives.py     # Describe, value counts, quick histograms
│   ├── bootstrap_ci.py              # Non-parametric CI for A–B mean differences
│   ├── fairness_checks.py           # Subgroup disparity table
│   ├── data_validation.py           # Missingness/outliers summary
│   ├── descriptive_stats.py         # Topline stats + example CIs
│   ├── sensitivity_analysis.py      # Remove top-N / normalization checks
│   ├── stats_tests.py               # Paired tests (e.g., 1st vs 2nd half)
│   ├── visualization.py             # Minute/period trend plots
│   └── run_pipeline.py              # Runs the full analysis sequence
├── seeds.json                       # Canonical seeds / run metadata
├── requirements.txt
├── .gitignore
└── LICENSE
```

> **Note:** `outputs/` mirrors `results/` so you can reference tables/figures consistently in your report.

---

## 🚀 Quickstart

1) (Optional) Create a virtual environment and install deps:
```bash
python -m venv .venv
source .venv/bin/activate        # Windows: .venv\Scripts\activate
pip install -r requirements.txt
```

2) **Data is already wired**: `data/raw/lacrosse_stats.csv` (period-level stats for 2023–2025).  
If you replace or add data, update `config/config.yaml`.

3) **Run the full pipeline** (writes tables & figures to `results/` and mirrors to `outputs/`):
```bash
python scripts/run_pipeline.py
```

4) **Targeted commands** (if you want to run individual analyses):

- Descriptive profile (describe, value-counts, histograms):
```bash
python scripts/analysis_descriptives.py   --data data/raw/lacrosse_stats.csv   --out outputs   --seed 42
```

- Bootstrap CI for a difference in means (e.g., goals: 1st half vs 2nd half):
```bash
python scripts/bootstrap_ci.py   --data data/raw/lacrosse_stats.csv   --col goals   --by period   --diff "2nd-1st"   --iters 5000   --out outputs/tables/goals_diff_ci.csv   --seed 4242
```

- Fairness/subgroup disparity (example uses year as subgroup; add others if present):
```bash
python scripts/fairness_checks.py   --data data/raw/lacrosse_stats.csv   --group-cols year   --target goals   --out outputs/tables/fairness_summary.csv
```

---

## 🧪 What’s Included in the Report

The stakeholder report (`reports/stakeholder_report.md`) includes:

- **Executive one-liner with tiered recommendations:**
  - **Operational (low risk):** Endurance + shot-selection micro-drills post-minute-30; instrument practices.
  - **Investigatory (medium risk):** A/B scrimmage trial of hydration + pacing; pre-registered metrics; 95% CIs.
  - **High-stakes (high risk):** Rotation/lineup changes contingent on monitored endurance metrics (human/HR/legal review).

- **Uncertainty:** 95% bootstrap confidence intervals; sensitivity checks (remove top 5%; normalization).  
- **Fairness:** Subgroup coverage & disparity table.  
- **Ethics/Legal:** FERPA/privacy; LLM labeling; human-in-the-loop for personnel actions.  
- **Appendix:** Full list of imported Task 4/5 artifacts; prompts & raw LLM outputs logged in `logs/llm_prompt_log.md`.

---

## 🛡️ Reproducibility

- All scripts accept `--seed` and print the seed used.  
- Canonical seeds and run markers live in `seeds.json`.  
- **Tables/figures** are materialized in `results/` and mirrored in `outputs/`.  

To pin your exact environment:
```bash
pip freeze > requirements.txt
```

---

## 📬 Submission

1) Push the repo to GitHub as **Task_07_Decision_Making** (keep large/raw private if needed).  
2) Email the public repo link to **jrstrome@syr.edu** (not Dr. Stromer-Galley).  
3) Report progress via the **Qualtrics** check-in by **Oct 1**.

---

## ✅ Notes

- LLM content from **Task 06** (sideline interview) is **clearly labeled** in the report and verified against data.  
- The consolidated dataset aggregates official SU Women’s Lacrosse period-level stats from **2023–2025** (Goals/SOG/Shots/Saves; OT where available).  
- High-stakes actions (e.g., personnel/lineup decisions) **require human review** and may require HR/Legal sign-off.
